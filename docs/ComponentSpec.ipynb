{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 515 LIME\n",
    "_Local Interpretable Model-agnostic Explanations_\n",
    "\n",
    "Spring 2019\n",
    "\n",
    "__Instructors:__\n",
    "Joseph L. Hellerstein (jlheller@uw.edu)\n",
    "\n",
    "David Beck (dacb@uw.edu)\n",
    "\n",
    "Bernease Herman (bernease@uw.edu)\n",
    "\n",
    "Sam Gao (gaoz6@cs.washington.edu)\n",
    "\n",
    "## Component Specification\n",
    "\n",
    "This component specification covers the proposed final project for the LIME team:\n",
    "\n",
    "Francisco Javier Salido Magos (javiers@uw.edu)\n",
    "\n",
    "Patrick King (pking70@uw.edu)\n",
    "\n",
    "Suman Bhagavathula (sumanbh@uw.edu)\n",
    "\n",
    "For a more general explanation of LIME, as well as links to the code and original paper by LIME's authors, you can go here: https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime\n",
    "\n",
    "### Software components\n",
    "\n",
    "Our project has two major modules, each of which can be broken down into multiple components. The two modules are:\n",
    "\n",
    "- Machine Learning (ML) model that takes a number of predictors as input, including college name, student major, type of school and other, and outputs a likely graduating salary bracket for students from that college/major combination.\n",
    "- A LIME module that can help a data scientist understand which predictors played a major role in defining the ML model's output for a particular set of inputs.\n",
    "\n",
    "#### _Machine Learning Model_\n",
    "\n",
    "For the ML model we will first need to merge, cleanse and prepare our datasets, which will likely require some amount of manual work to identify potential limitations in the datasets themselves, what the best way to encode the data is, and whether value imputation is necessary in some cases. Once the above decisions have been made, we will have to build a component we'll call data_cleanse that automates as many of these decisions as possible.\n",
    "\n",
    "A set of components will follow the above, that will enable us to train and test various ML models. For this step we plan to leverage functions available in SciKit and other Python packages that enable us to fit various types of potentially complex models, such as boosted trees, random forests, support vector machines with various kernels, and others.\n",
    "\n",
    "The final component for this first module will be employed to present results from the various approaches we will test, as well as visualizing them. To do this we plan to level components from Python packages such as Matplotlib.\n",
    "\n",
    "#### _LIME Module_\n",
    "\n",
    "The LIME module will approximate the underlying ML model with an interpretable one that is learned on randomly perturbed samples of an input/output instance of the underlying model. For purposes of this discussion we shall heretofore refer to the underlying ML model as the \"complex\" model, and to the LIME model as the \"simple\" model.\n",
    "\n",
    "The main idea of LIME is that we have some complex classifier, a random forest, boosted trees or a neural network, the workings of which cannot be explained in terms a human being can understand. We say that the complex ML model $f(x)$ is not _interpretable_ if, given a set of input predictors $x = (x_1, x_2, ...., x_m)$, an output $f(x)$ that is either a value indicating the probability that $x$ belongs to a certain class or a label designating that class, the reason why a particular $x_0$ results in a particular output $f(x_0)$ cannot be understood by a person, even if all the details of the model are known. Since the global workings of the complex model cannot be explained in human terms, we use simpler linear models to explain its local behavior in the vicinity of our chosen $(x, f(x))$.\n",
    "\n",
    "For purposes of this project we will limit the discussion to Machine Learning models for which the individual input predictors can be understood by humans, they are not engineered features, and that can be represented in tabular form.\n",
    "\n",
    "Inputs to the LIME module should be:\n",
    "\n",
    "- The single instance $x$, and corresponding complex model output $f(x)$ that we wish to interpret.\n",
    "- A description of the domain and probability distribution for each normalized predictor (mean $m = 0$ and standard deviation $\\sigma = 1$), encoded in the form of one histogram for each predictor in the model.\n",
    "- The complex model itself, which we will use to compute labels for a number of perturbed samples that will be generated by the module.\n",
    "\n",
    "The LIME module will have three main components:\n",
    "\n",
    "Inputs to the first component, $lime\\_sampler$, are the same as those for the entire LIME module, and the output will be a set of $n$ randomized samples of the complex model's behavior. Samples are generated by randomly chosing a value from each predictor/histogram, to form a randomized instance $z_i = (z_{i,1}, z_{i,2}, ...., z_{i,m})$, which is then provided as input to the complex model to obtain the corresponding output $f(z_i)$. The total number of randomized samples we generate, $n$, should be large, and these samples will be distributed all over the sample space.\n",
    "\n",
    "The second component, $lime\\_fit$, will take the set of randomized samples generated by $lime\\_sampler$ as input, and output a linear model, the simple model, that describes the behavior of the complex model in the vicinity of the input instance $x$. To do this, $lime\\_fit$ will need to execute two steps:\n",
    "\n",
    "1.- Compute a proximity measure/weight for each random sample. Since $lime\\_fit$ produces a set of randomized samples that are distributed across the entire sample space, we'll use this proximity measure $\\pi_x(z_i)$ to penalize the samples based on how distant they are from $x$. The further away $z_i$ is from $x$, the greater the penalty:\n",
    "\n",
    "$$\\pi_x(z_i) = \\exp^{-\\frac{D(x,z_i)^2}{\\sigma}}$$ \n",
    "\n",
    "where $D(x,z_i)$ is the L2 distance: \n",
    "\n",
    "$$D(x,z_i)^2 = (x_1 - z_{i,1})^2 + (x_2 - z_{i,2})^2 + .... + (x_m - z_{i,m})^2$$\n",
    "\n",
    "2.- Fit a linear model using the LASSO algorithm, with $x$ and the set of perturbed samples $z_1, z_2, ...., z_n$ as inputs. Thus, we wish to find:\n",
    "\n",
    "$$arg min_g \\sum_{i} \\pi_x(z_i)(f(z_i) - wz_i)^2 + \\lambda|w| + \\Omega(k)$$ \n",
    "\n",
    "where: \n",
    "\n",
    "$$g(z_i) = w_1 z_{i,1} + w_2z_{i,2} + .... + w_mz_{i,m}$$\n",
    "\n",
    "and $w$ is the set of coefficients $w_1, w_2, ...., w_m$ assigned by the linear model to each predictor, and $\\Omega(k)$ is a penalty term based on the number $k$ of non-zero elements in $w$.\n",
    "\n",
    "To fit the model we must employ the shrinkage method LASSO, as it shrinks the magnitued of those linear regression coefficients $w$ that are less correlated to the model's output, effectively helping us reduce the complexity of the simple model by reducing the number of non-zero predictors it uses.\n",
    "\n",
    "Our third component, $lime\\_result$, will generate a human-readable output that will facilitate interpretation of the complex ML model's behavior in the locality of the selected input instance. For this third component we will most likely leverage ML functions from variouis Python packages, such as Matplotlib.\n",
    "\n",
    "### Interactions to accomplish use cases\n",
    "\n",
    "The interaction is quite simple. The first module is the ML model that the data scientist needs to understand. Since the model is complex, direct interpretation of its output would require too much effort or is simply not possible in human terms.\n",
    "\n",
    "In order to gain insight, the data scientist needs to develop intuition on how the predictors at the input of the model affect its output classification, for each test instance. Given that we are dealing with a complex ML model, we use LIME to provide local explanations that will enable the data scientist to acquire intuition of what drive's the model's decisions in the vicinity of each specific test instance that are to be interpreted.\n",
    "\n",
    "### Preliminary plan\n",
    "\n",
    "Our preliminary plan consists of a two-pronged approach:\n",
    "\n",
    "For module one, the Machine Learning model:\n",
    "\n",
    "- Inspection of the datasets we plan to employ.\n",
    "- Implementation of the data_cleanse component.\n",
    "- Fitting of a number of ML models to classify colleges and majors into potential salary brackets.\n",
    "\n",
    "For the LIME module:\n",
    "\n",
    "- Do additional research on some of the mathematical and logistic subtleties of sampling and optimization for LIME.\n",
    "- Build and test the lime_sampler.\n",
    "- Build and test the lime_fit.\n",
    "- Build and test the lime_result.\n",
    "- Do end-to-end testing of the components.\n",
    "\n",
    "Once the above steps have been completed, we will evaluate the outputs of the ML model(s) using LIME and produce the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
