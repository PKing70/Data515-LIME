{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "\n",
    "# Code has NOT been checked for PEP8 yet.\n",
    "\n",
    "# Reading the contents of the iris dataset for testing purposes.\n",
    "iris = datasets.load_iris()\n",
    "# iris = np.column_stack((iris.data, iris.target))\n",
    "\n",
    "# Number of perturbed samples to be generated.\n",
    "n = 10000 \n",
    "# Number of bins for the histograms of continous attributes.\n",
    "num_bins = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a decision tree model to the iris dataset.\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=iris.feature_names,\n",
    "                                class_names=iris.target_names,\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used to generate perturbed samples.\n",
    "\n",
    "def discrete_bucketize(np_vector):\n",
    "    \"\"\"\n",
    "    Estimates the histogram buckets for a one-dimension, discrete valued dataset.\n",
    "    \n",
    "    Input is the vector, np_vector, of discrete values that is to be bucketized.\n",
    "    Outputs are two vectors. The first, named values, contains the normalized version of the unique values\n",
    "    found in np_vector. Normalized to mean zero and unit variance.\n",
    "    The second output vector, named multinom_rand, contains the multinomial probability distribution for the\n",
    "    elements of the values vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    values,freqs = np.unique(np_vector, return_counts=True)\n",
    "    freqs = freqs/np.sum(freqs)\n",
    "    values = values.astype(float)\n",
    "    values = preprocessing.scale(values)\n",
    "    multinom_rand = np.random.multinomial(n, freqs, 1)[0]\n",
    "    return(values, multinom_rand)\n",
    "\n",
    "\n",
    "def continuous_bucketize(num_bins, np_vector):\n",
    "    \"\"\"\n",
    "    Estimates the histogram buckets for a one-dimension, continous valued dataset.\n",
    "    \n",
    "    Inputs are the desired number of bins for the histogram, num_bins, and np_vector, the vector of continous\n",
    "    values that are to be bucketized. \n",
    "    Outputs are two vectors. The first, named h_bins, is a vector of length num_bins + 1 that lists the values\n",
    "    corresponding to the bin edges in the histogram, after they are normalized to mean zero and unit variance.\n",
    "    The second output vector, named freqs, contains the probabilities that a randomly generated element will\n",
    "    belong in each of the histogram's bins.\n",
    "    \"\"\"\n",
    "    \n",
    "    np_vector = preprocessing.scale(np_vector)\n",
    "    freqs, h_bins = np.histogramdd(np_vector, bins = num_bins)\n",
    "    freqs = freqs/np.sum(freqs)\n",
    "    h_bins = np.asarray(h_bins[0])\n",
    "    return(h_bins, freqs)\n",
    "\n",
    "\n",
    "def discrete_rand_samples(n, values, multinom_rand):\n",
    "    \"\"\"\n",
    "    Generates n random values following the multinomial probability distribution provided as input.\n",
    "    \n",
    "    Inputs are n, the number of random numbers that are to be generated, the vector values that lists\n",
    "    all the possible values that n can have, and multinom_rand which contains the multinomial probability\n",
    "    distribution that corresponds to each element in the values vector.\n",
    "    Output is the vector rand that contains n numbers chosen at random, with replacement, from the\n",
    "    elements in the values vector, following the multinomial probability distribution that was provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    rand = np.zeros(n)\n",
    "    k = 0\n",
    "    for j in range(0, len(values)):\n",
    "        rand[k:k+multinom_rand[j]] = values[j]\n",
    "        k = k + multinom_rand[j]\n",
    "    return(rand)\n",
    "\n",
    "\n",
    "def continuous_rand_samples(n, bins, freqs):\n",
    "    \"\"\"\n",
    "    Generates n random values following the probability distribution provided as input.\n",
    "    \n",
    "    Inputs are n, the number of random numbers that are to be generated, the vector bins that lists\n",
    "    the values the bin edges of the histogram, and the vector freqs that lists the probability that\n",
    "    a value that is randomly generated will be contained by the corresponding histogram bin.\n",
    "    Each random number that is generated is chosen from within a uniform probability distribution with \n",
    "    end values equal to those of a given histogram bin.\n",
    "    Output is the vector tot_samples that contains n random elements chosen as described above.\n",
    "    \"\"\"\n",
    "    \n",
    "    tot_samples = np.zeros(1)\n",
    "    samples_bins = np.random.multinomial(n, freqs, 1)\n",
    "    for j in range(0, len(freqs)):\n",
    "        samples = np.random.uniform(bins[j], bins[j+1], samples_bins[0][j])\n",
    "        tot_samples = np.hstack((tot_samples, samples))\n",
    "    tot_samples = tot_samples[1:, ]\n",
    "    return(tot_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code uses the iris dataset to evaluate the distributions of each attribute and generate\n",
    "# the perturbed samples. It calls the functions above.\n",
    "array = iris.target\n",
    "values, multinom_rand = discrete_bucketize(array)\n",
    "output = discrete_rand_samples(n, values, multinom_rand)\n",
    "\n",
    "perturbed_samples = np.zeros(n)\n",
    "for j in range(0, iris.data.shape[1] ):\n",
    "    array = iris.data[:, j]\n",
    "    h_bins, freqs = continuous_bucketize(num_bins, array)\n",
    "    output = continuous_rand_samples(n, h_bins, freqs)\n",
    "    perturbed_samples = np.vstack((perturbed_samples, output))\n",
    "perturbed_samples = np.transpose(perturbed_samples[1:,])\n",
    "# Once perturbed samples have been generated, the line of code below uses the decision tree we \n",
    "# fitted earlier, to get a predicted classification for each of our perturbed samples.\n",
    "class_perturb_samples = clf.predict(perturbed_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01254673, 0.012059  , 0.01277307, ..., 0.64967583, 0.67483733,\n",
       "       0.66559725])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the weights (this is not finished)\n",
    "inst_num = np.round(np.random.uniform(0, iris.data.shape[0], 1))\n",
    "inst_num = inst_num[0].astype(int)\n",
    "x = iris.data[inst_num,:]\n",
    "sigma = np.std(np.sum((perturbed_samples - x)**2, axis=1))\n",
    "weights = np.exp(-np.sum((perturbed_samples - x)**2, axis=1)/sigma)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99981604, 0.99834557, 0.99520183, 0.99040066])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore this code. Used for testing purposes.\n",
    "x = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\n",
    "y = ([1,1,1,1])\n",
    "sigma = np.var(np.sum((x-y)**2, axis=1))\n",
    "np.exp(-np.sum((x-y)**2, axis=1)/sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
